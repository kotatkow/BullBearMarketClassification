{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "447c14b2-64eb-40fe-a36c-74e3a29c1e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to ../data/data_split/standard_scaler_nasdaq\\dataset_split_visualization.png\n",
      "Visualization saved to ../data/data_split/standard_scaler_sp500\\dataset_split_visualization.png\n",
      "Run logistic regression model for standardscaled nasdaq data\n",
      "Visualization saved to ../data/data_split/standard_scaler_nasdaq\\dataset_split_visualization.png\n",
      "\n",
      "Training Logistic Regression with L1 regularization\n",
      "Accuracy with L1 regularization: 0.8655\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.57      0.62       188\n",
      "           1       0.90      0.94      0.92       786\n",
      "\n",
      "    accuracy                           0.87       974\n",
      "   macro avg       0.79      0.75      0.77       974\n",
      "weighted avg       0.86      0.87      0.86       974\n",
      "\n",
      "\n",
      "Training Logistic Regression with L2 regularization\n",
      "Accuracy with L2 regularization: 0.8655\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.57      0.62       188\n",
      "           1       0.90      0.94      0.92       786\n",
      "\n",
      "    accuracy                           0.87       974\n",
      "   macro avg       0.79      0.75      0.77       974\n",
      "weighted avg       0.86      0.87      0.86       974\n",
      "\n",
      "\n",
      "Evaluating Logistic Regression with L1 regularization\n",
      "Logistic Regression (L1) Confusion Matrix saved to ../output/logistic_regression/nasdaq\\logistic_regression_(l1)_confusion_matrix.png\n",
      "\n",
      "Evaluating Logistic Regression with L2 regularization\n",
      "Logistic Regression (L2) Confusion Matrix saved to ../output/logistic_regression/nasdaq\\logistic_regression_(l2)_confusion_matrix.png\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Best Cross-Validated Accuracy:\n",
      "0.8474532695560304\n",
      "\n",
      "Validation Accuracy: 0.8655030800821355\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.57      0.62       188\n",
      "           1       0.90      0.94      0.92       786\n",
      "\n",
      "    accuracy                           0.87       974\n",
      "   macro avg       0.79      0.75      0.77       974\n",
      "weighted avg       0.86      0.87      0.86       974\n",
      "\n",
      "Run logistic regression model for standardscaled sp500 data\n",
      "Visualization saved to ../data/data_split/standard_scaler_sp500\\dataset_split_visualization.png\n",
      "\n",
      "Training Logistic Regression with L1 regularization\n",
      "Accuracy with L1 regularization: 0.8946\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.58      0.64       195\n",
      "           1       0.92      0.96      0.94      1010\n",
      "\n",
      "    accuracy                           0.89      1205\n",
      "   macro avg       0.82      0.77      0.79      1205\n",
      "weighted avg       0.89      0.89      0.89      1205\n",
      "\n",
      "\n",
      "Training Logistic Regression with L2 regularization\n",
      "Accuracy with L2 regularization: 0.8946\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.58      0.64       195\n",
      "           1       0.92      0.96      0.94      1010\n",
      "\n",
      "    accuracy                           0.89      1205\n",
      "   macro avg       0.82      0.77      0.79      1205\n",
      "weighted avg       0.89      0.89      0.89      1205\n",
      "\n",
      "\n",
      "Evaluating Logistic Regression with L1 regularization\n",
      "Logistic Regression (L1) Confusion Matrix saved to ../output/logistic_regression/sp500\\logistic_regression_(l1)_confusion_matrix.png\n",
      "\n",
      "Evaluating Logistic Regression with L2 regularization\n",
      "Logistic Regression (L2) Confusion Matrix saved to ../output/logistic_regression/sp500\\logistic_regression_(l2)_confusion_matrix.png\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Best Hyperparameters:\n",
      "{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Best Cross-Validated Accuracy:\n",
      "0.879423487544484\n",
      "\n",
      "Validation Accuracy: 0.8946058091286307\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.58      0.64       195\n",
      "           1       0.92      0.96      0.94      1010\n",
      "\n",
      "    accuracy                           0.89      1205\n",
      "   macro avg       0.82      0.77      0.79      1205\n",
      "weighted avg       0.89      0.89      0.89      1205\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def split_and_visualize_dataset(file_path, output_dir):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training, validation, and test sets,\n",
    "    and saves a visualization of the split sizes.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the CSV file.\n",
    "    - output_dir: str, directory where the visualization will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None, but saves the visualization as a PNG file in the specified directory.\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X = data.drop(columns=[\"Market_Label\", \"Date\"])\n",
    "    y = data[\"Market_Label\"]\n",
    "\n",
    "    # First, split into training (70%) and temp (30% for validation and test)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Split the temp set further into validation (15%) and test (15%)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    "    )\n",
    "\n",
    "    # Visualize the split sizes\n",
    "    split_sizes = [len(X_train), len(X_val), len(X_test)]\n",
    "    labels = ['Training Set', 'Validation Set', 'Test Set']\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(labels, split_sizes, color=['blue', 'orange', 'green'])\n",
    "    plt.title('Dataset Split Visualization', fontsize=14)\n",
    "    plt.ylabel('Number of Entries', fontsize=12)\n",
    "    plt.xlabel('Dataset Splits', fontsize=12)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Save the plot\n",
    "    output_file = os.path.join(output_dir, \"dataset_split_visualization.png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Visualization saved to {output_file}\")\n",
    "    # Return the splits\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def train_logistic_regression(X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Trains Logistic Regression models with L1 and L2 regularization and evaluates them.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train, y_train: Training features and labels.\n",
    "    - X_val, y_val: Validation features and labels.\n",
    "\n",
    "    Returns:\n",
    "    - None, prints evaluation metrics.\n",
    "    \"\"\"\n",
    "    for penalty in [\"l1\", \"l2\"]:\n",
    "        print(f\"\\nTraining Logistic Regression with {penalty.upper()} regularization\")\n",
    "        model = LogisticRegression(penalty=penalty, solver=\"liblinear\", random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        print(f\"Accuracy with {penalty.upper()} regularization: {accuracy:.4f}\")\n",
    "        print(\"Classification Report:\\n\", classification_report(y_val, y_pred))\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, output_dir):\n",
    "    \"\"\"\n",
    "    Plots and saves a confusion matrix visualization.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: True labels.\n",
    "    - y_pred: Predicted labels.\n",
    "    - title: Title for the plot.\n",
    "    - output_dir: Directory where the plot will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[-1, 1])\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    plt.title(title)\n",
    "    \n",
    "    output_file = os.path.join(output_dir, f\"{title.replace(' ', '_').lower()}_confusion_matrix.png\")\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    print(f\"{title} Confusion Matrix saved to {output_file}\")\n",
    "\n",
    "def fine_tune_logistic_regression(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Fine-tunes Logistic Regression hyperparameters using GridSearchCV.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train, y_train: Training features and labels.\n",
    "\n",
    "    Returns:\n",
    "    - Best estimator from GridSearchCV.\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear']\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        LogisticRegression(random_state=42),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBest Hyperparameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"\\nBest Cross-Validated Accuracy:\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# split the standardscaled nasdaq data\n",
    "csv_file_path_standardscaled_nasdaq = \"../data/standardscaler/cleaned_normalized_combined_data_nasdaq.csv\"\n",
    "output_directory_standardscaled_nasdaq = \"../data/data_split/standard_scaler_nasdaq\"\n",
    "split_and_visualize_dataset(csv_file_path_standardscaled_nasdaq, output_directory_standardscaled_nasdaq)\n",
    "\n",
    "# split the standardscaled sp500\n",
    "csv_file_path_standardscaled_sp500 = \"../data/standardscaler/cleaned_normalized_combined_data_sp500.csv\"\n",
    "output_directory_standardscaled_sp500 = \"../data/data_split/standard_scaler_sp500\"\n",
    "split_and_visualize_dataset(csv_file_path_standardscaled_sp500, output_directory_standardscaled_sp500)\n",
    "\n",
    "print(\"Run logistic regression model for standardscaled nasdaq data\")\n",
    "\n",
    "# Run logistic regression model for standardscaled nasdaq data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_and_visualize_dataset(csv_file_path_standardscaled_nasdaq, output_directory_standardscaled_nasdaq)\n",
    "train_logistic_regression(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Train and plot confusion matrices for both L1 and L2 regularization - Standard-scaled nasdaq\n",
    "for penalty in [\"l1\", \"l2\"]:\n",
    "    print(f\"\\nEvaluating Logistic Regression with {penalty.upper()} regularization\")\n",
    "    model = LogisticRegression(penalty=penalty, solver=\"liblinear\", random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    output_dir_standardscaled_nasdaq = '../output/logistic_regression/nasdaq'\n",
    "    plot_confusion_matrix(y_val, y_pred, f\"Logistic Regression ({penalty.upper()})\", output_dir_standardscaled_nasdaq)\n",
    "\n",
    "# Perform fine-tuning of Logistic Regression - Standard-scaled nasdaq\n",
    "best_model = fine_tune_logistic_regression(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the validation set - Standard-scaled nasdaq\n",
    "y_pred = best_model.predict(X_val)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"Run logistic regression model for standardscaled sp500 data\")\n",
    "\n",
    "# Run logistic regression model for standardscaled sp500 data\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_and_visualize_dataset(csv_file_path_standardscaled_sp500, output_directory_standardscaled_sp500)\n",
    "train_logistic_regression(X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Train and plot confusion matrices for both L1 and L2 regularization - Standard-scaled sp500\n",
    "for penalty in [\"l1\", \"l2\"]:\n",
    "    print(f\"\\nEvaluating Logistic Regression with {penalty.upper()} regularization\")\n",
    "    model = LogisticRegression(penalty=penalty, solver=\"liblinear\", random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    output_dir_standardscaled_sp500 = '../output/logistic_regression/sp500'\n",
    "    plot_confusion_matrix(y_val, y_pred, f\"Logistic Regression ({penalty.upper()})\", output_dir_standardscaled_sp500)\n",
    "\n",
    "# Perform fine-tuning of Logistic Regression - Standard-scaled sp500\n",
    "best_model = fine_tune_logistic_regression(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model on the validation set - Standard-scaled sp500\n",
    "y_pred = best_model.predict(X_val)\n",
    "print(\"\\nValidation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e5f89-dee6-413b-87b3-f91dc5290f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
